{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data - Google Colab Only\n",
        "\n",
        "If we're running on Colab, we have to clone the whole repository so we can access to the dataset."
      ],
      "metadata": {
        "id": "7b9WJd0C8rOl"
      },
      "id": "7b9WJd0C8rOl"
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    GITHUB_REPO = 'https://github.com/vquanghuy/mri-image-segmentation'\n",
        "    GITHUB_DIR = '/content/mri-image-segmentation'\n",
        "    CLONE_COMMAND = f'git clone {GITHUB_REPO}'\n",
        "\n",
        "\n",
        "    !{CLONE_COMMAND} # type: ignore\n",
        "    %cd {GITHUB_DIR}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w57lDwAj803V",
        "outputId": "b817c35d-ca8d-413e-ad2e-ab059c8956d5"
      },
      "id": "w57lDwAj803V",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'mri-image-segmentation' already exists and is not an empty directory.\n",
            "/content/mri-image-segmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGrNib-1B5_k",
        "outputId": "527a4fe5-fe35-4bf1-d3a6-92693bbc558b"
      },
      "id": "JGrNib-1B5_k",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mri-image-segmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05f135ff",
      "metadata": {
        "id": "05f135ff"
      },
      "source": [
        "## UNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0bab23a",
      "metadata": {
        "id": "e0bab23a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import math\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow.keras.backend as tfback\n",
        "\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D, UpSampling3D, \\\n",
        "                    Activation, BatchNormalization, PReLU, Conv3DTranspose, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical, Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0149ece6",
      "metadata": {
        "id": "0149ece6",
        "outputId": "5c24ead3-592c-4db3-c465-5e3229697d2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Jul 30 19:23:40 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 511.79       Driver Version: 511.79       CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
            "|  0%   41C    P8     9W / 170W |    503MiB / 12288MiB |     14%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1452    C+G   ...ontend\\Docker Desktop.exe    N/A      |\n",
            "|    0   N/A  N/A      2088    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
            "|    0   N/A  N/A      2608    C+G                                   N/A      |\n",
            "|    0   N/A  N/A      3300    C+G   ...werToys.ColorPickerUI.exe    N/A      |\n",
            "|    0   N/A  N/A      3320    C+G   ...ck\\app-4.27.154\\slack.exe    N/A      |\n",
            "|    0   N/A  N/A      3420    C+G   ...\\PowerToys.FancyZones.exe    N/A      |\n",
            "|    0   N/A  N/A      5408    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
            "|    0   N/A  N/A      6976    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
            "|    0   N/A  N/A      7732    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
            "|    0   N/A  N/A      8088    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A      9008    C+G   ...werToys.PowerLauncher.exe    N/A      |\n",
            "|    0   N/A  N/A      9408    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
            "|    0   N/A  N/A     12164    C+G   ...onnect\\OpenVPNConnect.exe    N/A      |\n",
            "|    0   N/A  N/A     14300    C+G   ...root\\Office16\\WINWORD.EXE    N/A      |\n",
            "|    0   N/A  N/A     14752    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A     20896    C+G   ...ram Files\\LGHUB\\lghub.exe    N/A      |\n",
            "|    0   N/A  N/A     22940    C+G   ...logioptionsplus_agent.exe    N/A      |\n",
            "|    0   N/A  N/A     23452    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     24560    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
            "|    0   N/A  N/A     24972    C+G   ...e\\PhoneExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     31168    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
            "|    0   N/A  N/A     31460    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f32e5cb5-2b5f-4750-b2cf-f942e994920e",
      "metadata": {
        "id": "f32e5cb5-2b5f-4750-b2cf-f942e994920e",
        "outputId": "fbd44bfe-09ee-4260-e9a1-ca8851452142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPU\n"
          ]
        }
      ],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78269982",
      "metadata": {
        "id": "78269982"
      },
      "outputs": [],
      "source": [
        "# For GPU - use channels_first, otherwise use channel_last\n",
        "tfback.set_image_data_format(\"channels_first\") # For GPU\n",
        "# tfback.set_image_data_format(\"channels_last\") # For CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cb08020-5590-4bce-a9f2-e7e90843b121",
      "metadata": {
        "id": "8cb08020-5590-4bce-a9f2-e7e90843b121"
      },
      "source": [
        "## Build UNet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc5b4903",
      "metadata": {
        "id": "cc5b4903"
      },
      "outputs": [],
      "source": [
        "# Credit to: https://github.com/ellisdg/3DUnetCNN\n",
        "def create_convolution_block(input_layer, n_filters, batch_normalization=False,\n",
        "                             kernel=(3, 3, 3), activation=None,\n",
        "                             padding='same', strides=(1, 1, 1),\n",
        "                             instance_normalization=False):\n",
        "    \"\"\"\n",
        "    :param strides:\n",
        "    :param input_layer:\n",
        "    :param n_filters:\n",
        "    :param batch_normalization:\n",
        "    :param kernel:\n",
        "    :param activation: Keras activation layer to use. (default is 'relu')\n",
        "    :param padding:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    layer = Conv3D(n_filters, kernel, padding=padding, strides=strides)(\n",
        "        input_layer)\n",
        "    if activation is None:\n",
        "        return Activation('relu')(layer)\n",
        "    else:\n",
        "        return activation()(layer)\n",
        "\n",
        "\n",
        "def get_up_convolution(n_filters, pool_size, kernel_size=(2, 2, 2),\n",
        "                       strides=(2, 2, 2),\n",
        "                       deconvolution=False):\n",
        "    if deconvolution:\n",
        "        return Conv3DTranspose(filters=n_filters, kernel_size=kernel_size,\n",
        "                               strides=strides)\n",
        "    else:\n",
        "        return UpSampling3D(size=pool_size)\n",
        "\n",
        "def unet_model_3d(loss_function, input_shape=(4, 160, 160, 16),\n",
        "                  pool_size=(2, 2, 2), n_labels=3,\n",
        "                  initial_learning_rate=0.00001,\n",
        "                  deconvolution=False, depth=4, n_base_filters=32,\n",
        "                  include_label_wise_dice_coefficients=False, metrics=[],\n",
        "                  batch_normalization=False, activation_name=\"sigmoid\"):\n",
        "    \"\"\"\n",
        "    Builds the 3D UNet Keras model.f\n",
        "    :param metrics: List metrics to be calculated during model training (default is dice coefficient).\n",
        "    :param include_label_wise_dice_coefficients: If True and n_labels is greater than 1, model will report the dice\n",
        "    coefficient for each label as metric.\n",
        "    :param n_base_filters: The number of filters that the first layer in the convolution network will have. Following\n",
        "    layers will contain a multiple of this number. Lowering this number will likely reduce the amount of memory required\n",
        "    to train the model.\n",
        "    :param depth: indicates the depth of the U-shape for the model. The greater the depth, the more max pooling\n",
        "    layers will be added to the model. Lowering the depth may reduce the amount of memory required for training.\n",
        "    :param input_shape: Shape of the input data (n_chanels, x_size, y_size, z_size). The x, y, and z sizes must be\n",
        "    divisible by the pool size to the power of the depth of the UNet, that is pool_size^depth.\n",
        "    :param pool_size: Pool size for the max pooling operations.\n",
        "    :param n_labels: Number of binary labels that the model is learning.\n",
        "    :param initial_learning_rate: Initial learning rate for the model. This will be decayed during training.\n",
        "    :param deconvolution: If set to True, will use transpose convolution(deconvolution) instead of up-sampling. This\n",
        "    increases the amount memory required during training.\n",
        "    :return: Untrained 3D UNet Model\n",
        "    \"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "    current_layer = inputs\n",
        "    levels = list()\n",
        "\n",
        "    # add levels with max pooling\n",
        "    for layer_depth in range(depth):\n",
        "        layer1 = create_convolution_block(input_layer=current_layer,\n",
        "                                          n_filters=n_base_filters * (\n",
        "                                                  2 ** layer_depth),\n",
        "                                          batch_normalization=batch_normalization)\n",
        "        layer2 = create_convolution_block(input_layer=layer1,\n",
        "                                          n_filters=n_base_filters * (\n",
        "                                                  2 ** layer_depth) * 2,\n",
        "                                          batch_normalization=batch_normalization)\n",
        "        if layer_depth < depth - 1:\n",
        "            current_layer = MaxPooling3D(pool_size=pool_size)(layer2)\n",
        "            levels.append([layer1, layer2, current_layer])\n",
        "        else:\n",
        "            current_layer = layer2\n",
        "            levels.append([layer1, layer2])\n",
        "\n",
        "    # add levels with up-convolution or up-sampling\n",
        "    for layer_depth in range(depth - 2, -1, -1):\n",
        "        up_convolution = get_up_convolution(pool_size=pool_size,\n",
        "                                            deconvolution=deconvolution,\n",
        "                                            n_filters=\n",
        "                                            current_layer.shape[1])(\n",
        "            current_layer)\n",
        "        concat = concatenate([up_convolution, levels[layer_depth][1]], axis=1)\n",
        "        current_layer = create_convolution_block(\n",
        "            n_filters=levels[layer_depth][1].shape[1],\n",
        "            input_layer=concat, batch_normalization=batch_normalization)\n",
        "        current_layer = create_convolution_block(\n",
        "            n_filters=levels[layer_depth][1].shape[1],\n",
        "            input_layer=current_layer,\n",
        "            batch_normalization=batch_normalization)\n",
        "\n",
        "    final_convolution = Conv3D(n_labels, (1, 1, 1))(current_layer)\n",
        "    act = Activation(activation_name)(final_convolution)\n",
        "    model = Model(inputs=inputs, outputs=act)\n",
        "\n",
        "    if not isinstance(metrics, list):\n",
        "        metrics = [metrics]\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=initial_learning_rate), loss=loss_function,\n",
        "                  metrics=metrics)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "353ef9d9",
      "metadata": {
        "id": "353ef9d9"
      },
      "outputs": [],
      "source": [
        "def soft_dice_loss(y_true, y_pred, axis=(1, 2, 3), \n",
        "                   epsilon=0.00001):\n",
        "    dice_numerator = 2 * tfback.sum(y_true * y_pred, axis=axis) + epsilon\n",
        "    dice_denominator = tfback.sum(y_true**2, axis=axis) + tfback.sum(y_pred**2, axis=axis) + epsilon\n",
        "    dice_loss = 1 - tfback.mean(dice_numerator/dice_denominator)\n",
        "\n",
        "    return dice_loss\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, axis=(1, 2, 3), \n",
        "                     epsilon=0.00001):\n",
        "    dice_numerator = 2 * tfback.sum(y_true * y_pred, axis=axis) + epsilon\n",
        "    dice_denominator = tfback.sum(y_true, axis=axis) + tfback.sum(y_pred, axis=axis) + epsilon\n",
        "    dice_coefficient = tfback.mean(dice_numerator/dice_denominator)\n",
        "    \n",
        "    return dice_coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10b8c91f",
      "metadata": {
        "id": "10b8c91f"
      },
      "outputs": [],
      "source": [
        "model = unet_model_3d(loss_function=soft_dice_loss, metrics=[dice_coefficient], depth=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1e7adcf",
      "metadata": {
        "id": "f1e7adcf",
        "outputId": "34d2ee10-f665-472b-d29c-eb0ec32f2b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 4, 160, 160, 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv3d (Conv3D)                 (None, 32, 160, 160, 3488        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 160, 160, 0           conv3d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 64, 160, 160, 55360       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64, 160, 160, 0           conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D)    (None, 64, 80, 80, 8 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2 (Conv3D)               (None, 64, 80, 80, 8 110656      max_pooling3d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 80, 80, 8 0           conv3d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_3 (Conv3D)               (None, 128, 80, 80,  221312      activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 128, 80, 80,  0           conv3d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3D)  (None, 128, 40, 40,  0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_4 (Conv3D)               (None, 128, 40, 40,  442496      max_pooling3d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 128, 40, 40,  0           conv3d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_5 (Conv3D)               (None, 256, 40, 40,  884992      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 256, 40, 40,  0           conv3d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3D)  (None, 256, 20, 20,  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_6 (Conv3D)               (None, 256, 20, 20,  1769728     max_pooling3d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 256, 20, 20,  0           conv3d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_7 (Conv3D)               (None, 512, 20, 20,  3539456     activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 512, 20, 20,  0           conv3d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3D)  (None, 512, 10, 10,  0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_8 (Conv3D)               (None, 512, 10, 10,  7078400     max_pooling3d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 512, 10, 10,  0           conv3d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_9 (Conv3D)               (None, 1024, 10, 10, 14156800    activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 1024, 10, 10, 0           conv3d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d (UpSampling3D)    (None, 1024, 20, 20, 0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1536, 20, 20, 0           up_sampling3d[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_10 (Conv3D)              (None, 512, 20, 20,  21234176    concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 512, 20, 20,  0           conv3d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_11 (Conv3D)              (None, 512, 20, 20,  7078400     activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 512, 20, 20,  0           conv3d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d_1 (UpSampling3D)  (None, 512, 40, 40,  0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 768, 40, 40,  0           up_sampling3d_1[0][0]            \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_12 (Conv3D)              (None, 256, 40, 40,  5308672     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 256, 40, 40,  0           conv3d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_13 (Conv3D)              (None, 256, 40, 40,  1769728     activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 256, 40, 40,  0           conv3d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d_2 (UpSampling3D)  (None, 256, 80, 80,  0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 384, 80, 80,  0           up_sampling3d_2[0][0]            \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_14 (Conv3D)              (None, 128, 80, 80,  1327232     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 128, 80, 80,  0           conv3d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_15 (Conv3D)              (None, 128, 80, 80,  442496      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 128, 80, 80,  0           conv3d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d_3 (UpSampling3D)  (None, 128, 160, 160 0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 192, 160, 160 0           up_sampling3d_3[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_16 (Conv3D)              (None, 64, 160, 160, 331840      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 64, 160, 160, 0           conv3d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_17 (Conv3D)              (None, 64, 160, 160, 110656      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 64, 160, 160, 0           conv3d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_18 (Conv3D)              (None, 3, 160, 160,  195         activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 3, 160, 160,  0           conv3d_18[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 65,866,083\n",
            "Trainable params: 65,866,083\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6255f895-1c82-4d4c-8062-d031b9309abb",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "6255f895-1c82-4d4c-8062-d031b9309abb"
      },
      "source": [
        "## Train with Volume Data Generator"
      ]
    },
    {
      "cell_type": "raw",
      "id": "4f6ad1e2-8e4f-4b7c-a1d1-272fbef850e1",
      "metadata": {
        "id": "4f6ad1e2-8e4f-4b7c-a1d1-272fbef850e1"
      },
      "source": [
        "class VolumeDataGenerator(Sequence):\n",
        "    def __init__(self,\n",
        "                 sample_list,\n",
        "                 base_dir,\n",
        "                 batch_size=1,\n",
        "                 shuffle=True,\n",
        "                 dim=(160, 160, 16),\n",
        "                 num_channels=4,\n",
        "                 num_classes=3,\n",
        "                 verbose=1):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.base_dir = base_dir\n",
        "        self.dim = dim\n",
        "        self.num_channels = num_channels\n",
        "        self.num_classes = num_classes\n",
        "        self.verbose = verbose\n",
        "        self.sample_list = sample_list\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.sample_list))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.sample_list) / self.batch_size))\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples'\n",
        "\n",
        "        # Initialization\n",
        "        X = np.zeros((self.batch_size, self.num_channels, *self.dim),\n",
        "                     dtype=np.float64)\n",
        "        y = np.zeros((self.batch_size, self.num_classes, *self.dim),\n",
        "                     dtype=np.float64)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            if self.verbose == 1:\n",
        "                print(\"Training on: %s\" % self.base_dir + ID)\n",
        "            with h5py.File(os.path.join(self.base_dir, ID), 'r') as f:\n",
        "                X[i] = np.array(f.get(\"x\"))\n",
        "                # remove the background class\n",
        "                y[i] = np.moveaxis(np.array(f.get(\"y\")), 3, 0)[1:]\n",
        "        return X, y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[\n",
        "                  index * self.batch_size: (index + 1) * self.batch_size]\n",
        "        # Find list of IDs\n",
        "        sample_list_temp = [self.sample_list[k] for k in indexes]\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(sample_list_temp)\n",
        "\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "raw",
      "id": "ff0fcfa5-b927-4823-8791-33d86240c81f",
      "metadata": {
        "id": "ff0fcfa5-b927-4823-8791-33d86240c81f"
      },
      "source": [
        "DATA_DIR = \"./Sample_Data\"\n",
        "IMAGE_DIMENSION = (160, 160, 16)\n",
        "\n",
        "with open(os.path.join(base_dir, \"dataset.json\")) as json_file:\n",
        "    dataset = json.load(json_file)\n",
        "    \n",
        "train_generator = VolumeDataGenerator(dataset[\"training\"], \\\n",
        "                                            DATA_DIR, \\\n",
        "                                            batch_size=2, \\\n",
        "                                            dim=IMAGE_DIMENSION, \\\n",
        "                                            verbose=0)\n",
        "# valid_generator = utils.VolumeDataGenerator(config[\"valid\"], \\\n",
        "#                                             os.path.join(base_dir, \"valid\"), \\\n",
        "#                                             batch_size=2, \\\n",
        "#                                             dim=(160, 160, 16), \\\n",
        "#                                             verbose=0)\n",
        "\n",
        "# steps_per_epoch = 30\n",
        "# n_epochs=50\n",
        "# validation_steps = 30\n",
        "\n",
        "# model.fit(train_generator, \\\n",
        "#         steps_per_epoch=steps_per_epoch, \\\n",
        "#         epochs=n_epochs, \\\n",
        "#         use_multiprocessing=True, \\\n",
        "#         validation_data=valid_generator, \\\n",
        "#         validation_steps=validation_steps, \\\n",
        "#         verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13d13680-01c6-4d31-a69d-5d1f2a098e7b",
      "metadata": {
        "id": "13d13680-01c6-4d31-a69d-5d1f2a098e7b"
      },
      "source": [
        "## Train with Sequence"
      ]
    },
    {
      "cell_type": "raw",
      "id": "f2f7f7de-55ee-454f-9c35-3267b0e2e63e",
      "metadata": {
        "id": "f2f7f7de-55ee-454f-9c35-3267b0e2e63e"
      },
      "source": [
        "class MSDSequence(Sequence):\n",
        "    def __init__(self, sample_list, data_path, batch_size, sample_size):\n",
        "        self.sample_list = sample_list\n",
        "        self.data_path = data_path\n",
        "        self.batch_size = batch_size\n",
        "        self.sample_size = sample_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(self.sample_size / self.batch_size)\n",
        "    \n",
        "    def __load_data(self, image_file_path, label_file_path):\n",
        "        with open(image_file_path, 'rb') as f:\n",
        "            X = np.load(f)\n",
        "        with open(label_file_path, 'rb') as f:\n",
        "            y = np.load(f)\n",
        "\n",
        "        return X,y\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_list = self.sample_list[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_x = []\n",
        "        batch_y = []\n",
        "        \n",
        "        for item in batch_list:\n",
        "            X, y = self.__load_data( \\\n",
        "                os.path.join(self.data_path, item['image']), \\\n",
        "                os.path.join(self.data_path, item['label']), \\\n",
        "            )\n",
        "            \n",
        "            batch_x.append(X)\n",
        "            batch_y.append(y)\n",
        "\n",
        "        return np.array(batch_x), np.array(batch_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5137e31-a55b-4c42-965f-ad6b78a19766",
      "metadata": {
        "id": "c5137e31-a55b-4c42-965f-ad6b78a19766",
        "outputId": "c33790e8-9f31-4636-d967-004e025be375"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './Task01_BrainTumour_Optimized\\\\./imagesTr/BRATS_466.nii.gz'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5292/1933571686.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m model.fit(train_generator, \\\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1141\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1144\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1398\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1399\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1400\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1155\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1156\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1157\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[0;32m    932\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enqueuer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m     super(KerasSequenceAdapter, self).__init__(\n\u001b[0m\u001b[0;32m    935\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Shuffle is handed in the _make_callable override.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[0;32m    809\u001b[0m     \u001b[1;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m     \u001b[1;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m     \u001b[0mpeek\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    943\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 945\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m   def _handle_multiprocessing(self, x, workers, use_multiprocessing,\n",
            "\u001b[1;32m~\\Documents\\GitHub\\mri-image-segmentation\\MSDSequence.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             X, y = self.__load_data( \\\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Documents\\GitHub\\mri-image-segmentation\\MSDSequence.py\u001b[0m in \u001b[0;36m__load_data\u001b[1;34m(self, image_file_path, label_file_path)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__load_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Task01_BrainTumour_Optimized\\\\./imagesTr/BRATS_466.nii.gz'"
          ]
        }
      ],
      "source": [
        "from MSDSequence import MSDSequence \n",
        "\n",
        "# DATA_DIR = \"./Sample_Data\"\n",
        "DATA_DIR = \"./Task01_BrainTumour_Optimized\"\n",
        "\n",
        "with open(os.path.join(DATA_DIR, \"dataset.json\")) as json_file:\n",
        "    dataset = json.load(json_file)\n",
        "    \n",
        "numTraining = dataset[\"numTraining\"]\n",
        "trainingPropotion = math.ceil(0.8 * numTraining)\n",
        "\n",
        "trainingSet = dataset[\"training\"][trainingPropotion:]\n",
        "validSet = dataset[\"training\"][:trainingPropotion]\n",
        "    \n",
        "train_generator = MSDSequence(trainingSet, \\\n",
        "                              DATA_DIR, \\\n",
        "                              batch_size=10, \\\n",
        "                              sample_size=len(trainingSet))\n",
        "valid_generator = MSDSequence(validSet, \\\n",
        "                              DATA_DIR, \\\n",
        "                              batch_size=2, \\\n",
        "                              sample_size=len(validSet))\n",
        "\n",
        "steps_per_epoch = 20\n",
        "n_epochs=20\n",
        "validation_steps = 20\n",
        "\n",
        "model.fit(train_generator, \\\n",
        "        steps_per_epoch=steps_per_epoch, \\\n",
        "        epochs=n_epochs, \\\n",
        "        use_multiprocessing=True, \\\n",
        "        validation_data=valid_generator, \\\n",
        "        validation_steps=validation_steps, \\\n",
        "        verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc9ab380-7ead-4421-a373-cdb73466fcf7",
      "metadata": {
        "id": "fc9ab380-7ead-4421-a373-cdb73466fcf7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "name": "Train.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}